---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kafka-pvc
  namespace: infra
spec:
  storageClassName: local-hostpath
  volumeName: kafka-pv
  accessModes: [ReadWriteOnce]
  resources:
    requests:
      storage: 5Gi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka
  namespace: infra
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
        - name: kafka
          image: confluentinc/cp-kafka:latest
          ports:
            - containerPort: 9092
          env:
            # Override Kubernetes service-discovery injection (KAFKA_PORT=tcp://...)
            - name: KAFKA_PORT
              value: ""
            # KRaft mode — no Zookeeper required
            - name: CLUSTER_ID
              value: "H3sh4Kh3j7fN5VkZtQzTfw"
            - name: KAFKA_PROCESS_ROLES
              value: "broker,controller"
            - name: KAFKA_NODE_ID
              value: "1"
            - name: KAFKA_CONTROLLER_QUORUM_VOTERS
              value: "1@localhost:29093"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://kafka.infra.svc.cluster.local:9092"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "PLAINTEXT"
            - name: KAFKA_CONTROLLER_LISTENER_NAMES
              value: "CONTROLLER"
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
              value: "false"
            - name: KAFKA_LOG_DIRS
              value: /var/lib/kafka/data
            # Cap JVM heap so the process stays within the container memory limit.
            # Without this, Confluent Kafka defaults can exceed 1Gi and OOMKill.
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx512m -Xms256m"
          volumeMounts:
            - name: data
              mountPath: /var/lib/kafka
          resources:
            requests:
              cpu: 250m
              memory: 768Mi
            limits:
              cpu: 1000m
              memory: 2Gi
          readinessProbe:
            # TCP check avoids the chicken-and-egg: kafka-topics follows advertised
            # listener DNS which resolves to the Service (no endpoints until Ready)
            tcpSocket:
              port: 9092
            initialDelaySeconds: 30
            periodSeconds: 5
            failureThreshold: 6
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: kafka-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: infra
spec:
  selector:
    app: kafka
  ports:
    - name: internal
      port: 9092
      targetPort: 9092
  type: ClusterIP

---
# Job — pre-create required Kafka topics after Kafka is running.
# Re-apply safe: Job names are unique; use a new Job for re-runs.
apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-topic-init
  namespace: infra
spec:
  backoffLimit: 5
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: topic-creator
          image: confluentinc/cp-kafka:latest
          command:
            - sh
            - -c
            - |
              echo "Waiting for Kafka to be ready..."
              until kafka-topics --bootstrap-server kafka.infra.svc.cluster.local:9092 --list; do
                echo "Kafka not ready yet, retrying in 5s..."
                sleep 5
              done

              create_topic() {
                local topic=$1
                if kafka-topics --bootstrap-server kafka.infra.svc.cluster.local:9092 --describe --topic "$topic" &>/dev/null; then
                  echo "Topic '$topic' already exists."
                else
                  kafka-topics --bootstrap-server kafka.infra.svc.cluster.local:9092 \
                    --create --topic "$topic" \
                    --partitions 3 \
                    --replication-factor 1
                  echo "Topic '$topic' created."
                fi
              }

              create_topic "order.created"
              create_topic "inventory.updated"
              echo "All topics ready."
          resources:
            requests:
              cpu: 50m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 256Mi
